{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importo librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import eikon as ek\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "import datetime\n",
    "from datetime import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ek.set_app_id('THEWOODBRIDGECOMPANY.PYPY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardo titulares e IDs de noticias del último año"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardo titulares de noticias del último año, la API limita a 100 noticias pero con un bucle puedo concatenar más:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deb_abre, fin_abre = '2017-12-07T09:00:00', '2018-06-12T09:00:00'\n",
    "deb_cierra, fin_cierra = '2017-12-07T16:55:00', '2018-06-12T16:55:00'\n",
    "\n",
    "start_abre, end_abre = datetime.datetime.strptime(deb_abre, \"%Y-%m-%dT%H:%M:%S\"), \\\n",
    "                                    datetime.datetime.strptime(fin_abre, \"%Y-%m-%dT%H:%M:%S\")\n",
    "start_cierra, end_cierra = datetime.datetime.strptime(deb_cierra, \"%Y-%m-%dT%H:%M:%S\"), \\\n",
    "                                    datetime.datetime.strptime(fin_cierra, \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "dif = int((end_abre-start_abre).total_seconds()/(3600*24)) ## time difference in days\n",
    "\n",
    "fechas_iniciales = [(start_abre + datetime.timedelta(hours=24*x)).strftime(\"%Y-%m-%dT%H:%M:%S\") for x in range(dif+1)]\n",
    "fechas_finales = [(start_cierra + datetime.timedelta(hours=24*x)).strftime(\"%Y-%m-%dT%H:%M:%S\") for x in range(dif+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for fecha, fecha_fin in zip(fechas_iniciales,fechas_finales): \n",
    "    aux = ek.get_news_headlines('R:IBM.N AND Language:LEN', date_from = fecha, date_to = fecha_fin, count=20)\n",
    "    df = pd.concat([df, aux])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elementos = len(df.index)\n",
    "print(u'Tengo un total de %s noticias que analizar' %elementos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de sentimientos de las noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo 3 columnas para guardar variables que generaré posteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Polaridad'] = np.nan\n",
    "df['Subjetividad'] = np.nan\n",
    "df['Categorizacion'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un dataframe con los titulares de las noticias y los ID que ha asignado Thomson Reuters a esas noticias. Con ese ID seremos capaces de acceder a las noticias en sí y analizarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for indice, noticiaID in enumerate(df['storyId'].values): # Itero por todas las filas del dataframe\n",
    "    try:\n",
    "        texto = ek.get_news_story(noticiaID) # Obtengo el texto de cada una de las noticias\n",
    "        if texto:\n",
    "            soup = BeautifulSoup(texto,\"lxml\") # Creo un objeto BeautifulSoup a partir de nuestro artículo HTML\n",
    "            sents = TextBlob(soup.get_text()) # Paso el texto del artículo a TextBlob para que lo analice\n",
    "            df['Polaridad'].iloc[indice] = sents.sentiment.polarity # Guardo la polaridad del sentimiento en el dataframe\n",
    "            df['Subjetividad'].iloc[indice] = sents.sentiment.subjectivity # Guardo la subjetividad 0->objetiva 1->subjetiva\n",
    "            if sents.sentiment.polarity >= 0.05: # Categorizo las polaridades -1->negativa 1->positiva\n",
    "                score = 'Positivo'\n",
    "            elif  -.05 < sents.sentiment.polarity < 0.05:\n",
    "                score = 'Neutral'\n",
    "            else:\n",
    "                score = 'Negativo'\n",
    "            df['Categorizacion'].iloc[indice] = score \n",
    "            if indice%20==0: # Pongo un contador para ver por donde va el tema\n",
    "                print(u'Voy por el índice %s' %indice)\n",
    "    except:\n",
    "        pass\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizo el impacto de las noticias sobre el precio (ceteris paribus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo una serie temporal de precios en cada minuto, desde la fecha mínima de noticias. Ojo, como máximo devuelve 50 mil minutos por lo que tengo aproximadamente 6 meses de datos (va desde el presente hasta la fecha de inicio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"minuto = pd.DataFrame()\n",
    "for fecha, fecha_fin in zip(fechas_iniciales,fechas_finales): \n",
    "    aux = ek.get_timeseries([\"IBM.N\"], start_date = fecha, end_date = fecha_fin, interval='minute')\n",
    "    minuto = pd.concat([minuto, aux])\n",
    "minuto.tail()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inicio = df['versionCreated'].min().replace(hour=0,minute=0,second=0,microsecond=0).strftime('%Y/%m/%d')\n",
    "fin = df['versionCreated'].max().replace(hour=0,minute=0,second=0,microsecond=0).strftime('%Y/%m/%d')\n",
    "minuto = ek.get_timeseries([\"IBM.N\"], start_date=inicio, interval=\"minute\")\n",
    "minuto.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min(minuto.index), max(minuto.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defino variables con los precios en minutos posteriores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['2Minutos'] = np.nan\n",
    "df['5minutos'] = np.nan\n",
    "df['10minutos'] = np.nan\n",
    "df['30minutos'] = np.nan\n",
    "df['1hora'] = np.nan\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengo la variación en cada intervalo de tiempo como:\n",
    "$$\\triangle_{t\\rightarrow t+x} = \\Bigl ( \\frac{Valor_{t+x}}{Valor_t} -1\\Bigr) * 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for indice, fechaNoticia in enumerate(df['versionCreated'].values):\n",
    "    sTime = df['versionCreated'][indice]\n",
    "    sTime = sTime.replace(second=0,microsecond=0) # Quito segundos y micros para ir a nivel minuto\n",
    "    try:\n",
    "        t0 = minuto.iloc[minuto.index.get_loc(sTime),2] # Lo que vale al crearse la noticia\n",
    "        df['2Minutos'][indice] = ((minuto.iloc[minuto.index.get_loc((sTime + datetime.timedelta(minutes=2))),3]/(t0)-1)*100)\n",
    "        df['5minutos'][indice] = ((minuto.iloc[minuto.index.get_loc((sTime + datetime.timedelta(minutes=5))),3]/(t0)-1)*100)\n",
    "        df['10minutos'][indice] = ((minuto.iloc[minuto.index.get_loc((sTime + datetime.timedelta(minutes=10))),3]/(t0)-1)*100) \n",
    "        df['30minutos'][indice] = ((minuto.iloc[minuto.index.get_loc((sTime + datetime.timedelta(minutes=30))),3]/(t0)-1)*100)\n",
    "        df['1hora'][indice] = ((minuto.iloc[minuto.index.get_loc((sTime + datetime.timedelta(minutes=60))),3]/(t0)-1)*100)\n",
    "    except:\n",
    "        pass\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['Categorizacion']).mean()\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las noticias negativas hacen bajar las acciones de IBM de media en los 10 minutos siguientes un 0,14 por ciento, mientras que las buenas la hacen bajar un 0,011 por ciento. Ojo, esto está sesgado a las acciones de IBM pero lo que se deduce es que a muy corto plazo las noticias impactan en el precio de las acciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[~df.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positivos = df.loc[df['Categorizacion']=='Positivo'].groupby(df['versionCreated'].dt.\\\n",
    "                            strftime('%Y-%m-%d'))['Categorizacion'].count().sort_index().reset_index()\n",
    "negativos = df.loc[df['Categorizacion']=='Negativo'].groupby(df['versionCreated'].dt.\\\n",
    "                            strftime('%Y-%m-%d'))['Categorizacion'].count().sort_index().reset_index()\n",
    "neutrales = df.loc[df['Categorizacion']=='Neutral'].groupby(df['versionCreated'].dt.\\\n",
    "                            strftime('%Y-%m-%d'))['Categorizacion'].count().sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minuto_represento = minuto.reset_index()\n",
    "minuto_represento = minuto_represento[['Date','OPEN']].groupby(minuto_represento['Date'].\\\n",
    "                                                dt.strftime('%Y-%m-%d')).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "init_notebook_mode(connected=True)\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = positivos['versionCreated'],\n",
    "    y = positivos['Categorizacion'],\n",
    "    line = dict(color = 'green'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Noticias positivas',\n",
    "    yaxis='y2'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = negativos['versionCreated'],\n",
    "    y = negativos['Categorizacion'],\n",
    "    line = dict(color = 'red'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Noticias negativas',\n",
    "    yaxis='y2'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = neutrales['versionCreated'],\n",
    "    y = neutrales['Categorizacion'],\n",
    "    line = dict(color = 'orange'),\n",
    "    mode = 'lines+markers',\n",
    "    name = 'Noticias neutrales',\n",
    "    yaxis='y2'\n",
    ")\n",
    "trace3 = go.Scatter(\n",
    "    x = minuto_represento['Date'],\n",
    "    y = minuto_represento['OPEN'],\n",
    "    line=go.Line(shape='hv', color='black'),\n",
    "    mode = 'lines',\n",
    "    fill='tonexty',\n",
    "    name = 'Precio de las acciones'\n",
    ")\n",
    "datos = [trace0, trace1, trace2, trace3]\n",
    "\n",
    "layout = dict(title = u'Análisis de sentimiento de noticias sobre IBM',\n",
    "                xaxis = dict(title = u'Fecha'),\n",
    "                yaxis = dict(title = u'Precio de las acciones'),\n",
    "                yaxis2=dict(\n",
    "                    title=u'Número de noticias',\n",
    "                    overlaying='y',\n",
    "                    side='right'\n",
    "                )\n",
    "              )\n",
    "\n",
    "fig = dict(data=datos, layout=layout)\n",
    "iplot(fig, filename='analisis-noticias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('analisis_noticias_fichero.csv', encoding='utf-8', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
